{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13cf4729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading datasets...\n",
      " Successfully loaded all selected features, optimizing memory usage! \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "eicu_data_path = \"../eicu_data\"  \n",
    "\n",
    "columns_to_load = {\n",
    "    \"patient.csv\": [\"patientunitstayid\", \"age\", \"gender\", \"admissionheight\", \"admissionweight\", \"hospitaldischargestatus\",\"hospitaldischargeoffset\",\"hospitaladmitoffset\"],\n",
    "    \"apacheapsvar.csv\": [\"patientunitstayid\", \"albumin\", \"bilirubin\", \"bun\", \"creatinine\", \"glucose\", \"hematocrit\", \"meanbp\", \"pao2\", \"pco2\", \"ph\", \"respiratoryrate\", \"sodium\", \"urine\", \"wbc\"],\n",
    "    \"apachepatientresult.csv\": [\"patientunitstayid\", \"actualhospitalmortality\", \"actualicumortality\", \"apachescore\", \"acutephysiologyscore\", \"predictedhospitalmortality\", \"predictedicumortality\"],\n",
    "    \"apachepredvar.csv\": [\"patientunitstayid\", \"admitdiagnosis\", \"admitsource\", \"diabetes\", \"hepaticfailure\", \"immunosuppression\", \"leukemia\", \"metastaticcancer\", \"motor\", \"verbal\"],\n",
    "    \"vitalperiodic.csv\": [\"patientunitstayid\", \"heartrate\", \"respiration\", \"sao2\", \"temperature\", \"systemicdiastolic\", \"systemicmean\", \"systemicsystolic\"],\n",
    "    \"lab.csv\": [\"patientunitstayid\", \"labname\", \"labresult\"],\n",
    "    \"intakeoutput.csv\": [\"patientunitstayid\", \"intaketotal\", \"outputtotal\", \"nettotal\"],\n",
    "    \"respiratorycare.csv\": [\"patientunitstayid\", \"ventstartoffset\", \"ventendoffset\"],\n",
    "}\n",
    "\n",
    "print(\" Loading datasets...\")\n",
    "dataframes = {file.replace(\".csv\", \"\"): pd.read_csv(os.path.join(eicu_data_path, file), usecols=cols) for file, cols in columns_to_load.items()}\n",
    "\n",
    "patient_df = dataframes[\"patient\"]\n",
    "apache_apsvar_df = dataframes[\"apacheapsvar\"]\n",
    "apache_result_df = dataframes[\"apachepatientresult\"]\n",
    "apache_predvar_df = dataframes[\"apachepredvar\"]\n",
    "vitalperiodic_df = dataframes[\"vitalperiodic\"]\n",
    "lab_df = dataframes[\"lab\"]\n",
    "intakeoutput_df = dataframes[\"intakeoutput\"]\n",
    "respiratorycare_df = dataframes[\"respiratorycare\"]\n",
    "\n",
    "print(\" Successfully loaded all selected features, optimizing memory usage! \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c05538c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Reducing `intakeoutput_df`...\n",
      " `intakeoutput_df` reduced from 12,030,289 to 180,855 rows!\n"
     ]
    }
   ],
   "source": [
    "print(\" Reducing `intakeoutput_df`...\")\n",
    "intakeoutput_df = pd.read_csv(os.path.join(eicu_data_path, \"intakeoutput.csv\"), usecols=[\"patientunitstayid\", \"intaketotal\", \"outputtotal\", \"nettotal\"])\n",
    "\n",
    "intakeoutput_reduced = intakeoutput_df.groupby(\"patientunitstayid\").agg({\n",
    "    \"intaketotal\": [\"mean\", \"max\", \"min\", \"last\"],\n",
    "    \"outputtotal\": [\"mean\", \"max\", \"min\", \"last\"],\n",
    "    \"nettotal\": [\"mean\", \"max\", \"min\", \"last\"]\n",
    "})\n",
    "\n",
    "intakeoutput_reduced.columns = [\"_\".join(col).strip() for col in intakeoutput_reduced.columns]\n",
    "intakeoutput_reduced.reset_index(inplace=True)\n",
    "\n",
    "dataframes[\"intakeoutput\"] = intakeoutput_reduced\n",
    "\n",
    "print(f\" `intakeoutput_df` reduced from {len(intakeoutput_df):,} to {len(intakeoutput_reduced):,} rows!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc2fd210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Checking `lab` dataset size before transformation...\n",
      " `lab` dataset size before transformation: 39,132,531 rows\n",
      " Transforming `lab` dataset...\n",
      " `lab` dataset transformed successfully!\n",
      " `lab` dataset size after transformation: 193,160 rows\n",
      " `lab` dataset reduced by 99.51%\n"
     ]
    }
   ],
   "source": [
    "print(\" Checking `lab` dataset size before transformation...\")\n",
    "\n",
    "lab_initial_rows = len(dataframes[\"lab\"])\n",
    "print(f\" `lab` dataset size before transformation: {lab_initial_rows:,} rows\")\n",
    "\n",
    "print(\" Transforming `lab` dataset...\")\n",
    "\n",
    "valid_lab_tests = [\n",
    "    \"glucose\", \"creatinine\", \"sodium\", \"potassium\", \"chloride\", \"BUN\",\n",
    "    \"WBC x 1000\", \"Hgb\", \"platelets x 1000\", \"total bilirubin\", \"lactate\",\n",
    "    \"pH\", \"paO2\", \"paCO2\"\n",
    "]  \n",
    "lab_df = dataframes[\"lab\"][dataframes[\"lab\"][\"labname\"].isin(valid_lab_tests)]\n",
    "\n",
    "lab_df = lab_df.groupby([\"patientunitstayid\", \"labname\"])[\"labresult\"].agg([\"mean\", \"min\", \"max\"]).reset_index()\n",
    "\n",
    "lab_df = lab_df.pivot(index=\"patientunitstayid\", columns=\"labname\", values=[\"mean\", \"min\", \"max\"]).reset_index()\n",
    "\n",
    "lab_df.columns = [\"_\".join(col).strip() for col in lab_df.columns]\n",
    "lab_df.rename(columns={\"patientunitstayid_\": \"patientunitstayid\"}, inplace=True)\n",
    "\n",
    "dataframes[\"lab\"] = lab_df  \n",
    "\n",
    "print(\" `lab` dataset transformed successfully!\")\n",
    "\n",
    "\n",
    "lab_reduced_rows = len(dataframes[\"lab\"])\n",
    "print(f\" `lab` dataset size after transformation: {lab_reduced_rows:,} rows\")\n",
    "\n",
    "reduction_percentage = ((lab_initial_rows - lab_reduced_rows) / lab_initial_rows) * 100\n",
    "print(f\" `lab` dataset reduced by {reduction_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d710c99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientunitstayid</th>\n",
       "      <th>mean_BUN</th>\n",
       "      <th>mean_Hgb</th>\n",
       "      <th>mean_WBC x 1000</th>\n",
       "      <th>mean_chloride</th>\n",
       "      <th>mean_creatinine</th>\n",
       "      <th>mean_glucose</th>\n",
       "      <th>mean_lactate</th>\n",
       "      <th>mean_pH</th>\n",
       "      <th>mean_paCO2</th>\n",
       "      <th>...</th>\n",
       "      <th>max_creatinine</th>\n",
       "      <th>max_glucose</th>\n",
       "      <th>max_lactate</th>\n",
       "      <th>max_pH</th>\n",
       "      <th>max_paCO2</th>\n",
       "      <th>max_paO2</th>\n",
       "      <th>max_platelets x 1000</th>\n",
       "      <th>max_potassium</th>\n",
       "      <th>max_sodium</th>\n",
       "      <th>max_total bilirubin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141168</td>\n",
       "      <td>27.333333</td>\n",
       "      <td>12.566667</td>\n",
       "      <td>14.766667</td>\n",
       "      <td>101.333333</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>93.333333</td>\n",
       "      <td>12.2</td>\n",
       "      <td>7.16</td>\n",
       "      <td>39.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.95</td>\n",
       "      <td>131.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>7.20</td>\n",
       "      <td>46.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>140.0</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141178</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.70</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>273.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141179</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>107.333333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.70</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>146.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141194</td>\n",
       "      <td>27.357143</td>\n",
       "      <td>8.640000</td>\n",
       "      <td>7.920000</td>\n",
       "      <td>106.071429</td>\n",
       "      <td>2.108571</td>\n",
       "      <td>143.071429</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7.31</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.94</td>\n",
       "      <td>168.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>7.31</td>\n",
       "      <td>26.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141196</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>17.700000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>134.500000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.43</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.89</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.43</td>\n",
       "      <td>45.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   patientunitstayid   mean_BUN   mean_Hgb  mean_WBC x 1000  mean_chloride  \\\n",
       "0             141168  27.333333  12.566667        14.766667     101.333333   \n",
       "1             141178  11.000000  15.500000         7.600000     108.000000   \n",
       "2             141179  18.333333  12.500000         8.100000     107.333333   \n",
       "3             141194  27.357143   8.640000         7.920000     106.071429   \n",
       "4             141196  20.000000  10.600000        17.700000      98.000000   \n",
       "\n",
       "   mean_creatinine  mean_glucose  mean_lactate  mean_pH  mean_paCO2  ...  \\\n",
       "0         2.400000     93.333333          12.2     7.16        39.5  ...   \n",
       "1         0.700000     77.000000           NaN      NaN         NaN  ...   \n",
       "2         0.700000     80.000000           NaN      NaN         NaN  ...   \n",
       "3         2.108571    143.071429           1.5     7.31        26.0  ...   \n",
       "4         0.840000    134.500000           0.8     7.43        45.0  ...   \n",
       "\n",
       "   max_creatinine  max_glucose  max_lactate  max_pH  max_paCO2  max_paO2  \\\n",
       "0            2.95        131.0         12.2    7.20       46.0     121.0   \n",
       "1            0.70         77.0          NaN     NaN        NaN       NaN   \n",
       "2            0.70         96.0          NaN     NaN        NaN       NaN   \n",
       "3            2.94        168.0          1.9    7.31       26.0     100.0   \n",
       "4            0.89        144.0          0.8    7.43       45.0      70.0   \n",
       "\n",
       "   max_platelets x 1000  max_potassium  max_sodium  max_total bilirubin  \n",
       "0                 213.0            4.3       140.0                  5.2  \n",
       "1                 273.0            3.6       146.0                  0.4  \n",
       "2                 219.0            4.2       146.0                  NaN  \n",
       "3                 298.0            4.6       141.0                  0.4  \n",
       "4                 534.0            4.1       138.0                  0.3  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91afaa70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Checking `vitalperiodic` dataset size before aggregation...\n",
      " `vitalperiodic` dataset size before aggregation: 146,671,642 rows\n",
      " Aggregating `vitalperiodic` (keeping only mean values)...\n",
      " `vitalperiodic` successfully aggregated!\n",
      " `vitalperiodic` dataset size after aggregation: 192,831 rows\n",
      " `vitalperiodic` reduced by 99.87%\n"
     ]
    }
   ],
   "source": [
    "print(\" Checking `vitalperiodic` dataset size before aggregation...\")\n",
    "vital_initial_rows = len(dataframes[\"vitalperiodic\"])\n",
    "print(f\" `vitalperiodic` dataset size before aggregation: {vital_initial_rows:,} rows\")\n",
    "\n",
    "print(\" Aggregating `vitalperiodic` (keeping only mean values)...\")\n",
    "\n",
    "vital_aggregated = dataframes[\"vitalperiodic\"].groupby(\"patientunitstayid\").agg({\n",
    "    \"heartrate\": \"mean\",\n",
    "    \"respiration\": \"mean\",\n",
    "    \"temperature\": \"mean\",\n",
    "    \"sao2\": \"mean\",\n",
    "    \"systemicdiastolic\": \"mean\",\n",
    "    \"systemicmean\": \"mean\",\n",
    "    \"systemicsystolic\": \"mean\"\n",
    "}).reset_index()\n",
    "\n",
    "dataframes[\"vitalperiodic\"] = vital_aggregated\n",
    "\n",
    "print(\" `vitalperiodic` successfully aggregated!\")\n",
    "\n",
    "vital_reduced_rows = len(dataframes[\"vitalperiodic\"])\n",
    "print(f\" `vitalperiodic` dataset size after aggregation: {vital_reduced_rows:,} rows\")\n",
    "\n",
    "reduction_percentage = ((vital_initial_rows - vital_reduced_rows) / vital_initial_rows) * 100\n",
    "print(f\" `vitalperiodic` reduced by {reduction_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4b2045e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientunitstayid</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>respiration</th>\n",
       "      <th>temperature</th>\n",
       "      <th>sao2</th>\n",
       "      <th>systemicdiastolic</th>\n",
       "      <th>systemicmean</th>\n",
       "      <th>systemicsystolic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141168</td>\n",
       "      <td>110.557416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.325843</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>70.585366</td>\n",
       "      <td>92.707317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141178</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141179</td>\n",
       "      <td>91.233503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.717391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141194</td>\n",
       "      <td>85.401042</td>\n",
       "      <td>20.598958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.730689</td>\n",
       "      <td>50.636628</td>\n",
       "      <td>65.104348</td>\n",
       "      <td>92.828488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141196</td>\n",
       "      <td>82.305147</td>\n",
       "      <td>24.114815</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.509434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patientunitstayid   heartrate  respiration  temperature       sao2  \\\n",
       "0             141168  110.557416          NaN          NaN  86.325843   \n",
       "1             141178   88.000000          NaN          NaN  92.000000   \n",
       "2             141179   91.233503          NaN          NaN  98.717391   \n",
       "3             141194   85.401042    20.598958          NaN  98.730689   \n",
       "4             141196   82.305147    24.114815          NaN  95.509434   \n",
       "\n",
       "   systemicdiastolic  systemicmean  systemicsystolic  \n",
       "0          51.000000     70.585366         92.707317  \n",
       "1                NaN           NaN               NaN  \n",
       "2                NaN           NaN               NaN  \n",
       "3          50.636628     65.104348         92.828488  \n",
       "4                NaN           NaN               NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[\"vitalperiodic\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feff8f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133468353"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vitalperiodic_df['temperature'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e841fec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_df = dataframes[\"lab\"]  \n",
    "intakeoutput_df = dataframes[\"intakeoutput\"] \n",
    "vitalperiodic_df = dataframes[\"vitalperiodic\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "464e40d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Merging datasets...\n",
      " Merging dataset...\n",
      " Merging dataset...\n",
      " Merging dataset...\n",
      " Merging dataset...\n",
      " Merging dataset...\n",
      " Merging dataset...\n",
      " Merging dataset...\n",
      " Merging completed successfully!\n",
      " Merged dataset contains 1,908,519 rows and 100 columns.\n"
     ]
    }
   ],
   "source": [
    "print(\" Merging datasets...\")\n",
    "merged_df = patient_df.copy()\n",
    "datasets_to_merge = [apache_apsvar_df, apache_result_df, apache_predvar_df, lab_df, vitalperiodic_df, intakeoutput_df, respiratorycare_df]\n",
    "for df in datasets_to_merge:\n",
    "    print(\" Merging dataset...\")\n",
    "    merged_df = merged_df.merge(df, on=\"patientunitstayid\", how=\"left\")\n",
    "\n",
    "print(\" Merging completed successfully!\")\n",
    "num_rows, num_cols = merged_df.shape\n",
    "print(f\" Merged dataset contains {num_rows:,} rows and {num_cols} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bec9280d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['patientunitstayid', 'gender', 'age', 'admissionheight',\n",
       "       'hospitaladmitoffset', 'hospitaldischargeoffset',\n",
       "       'hospitaldischargestatus', 'admissionweight', 'urine', 'wbc',\n",
       "       'respiratoryrate', 'sodium', 'meanbp', 'ph', 'hematocrit', 'creatinine',\n",
       "       'albumin', 'pao2', 'pco2', 'bun', 'glucose', 'bilirubin',\n",
       "       'acutephysiologyscore', 'apachescore', 'predictedicumortality',\n",
       "       'actualicumortality', 'predictedhospitalmortality',\n",
       "       'actualhospitalmortality', 'admitsource', 'verbal', 'motor',\n",
       "       'admitdiagnosis', 'hepaticfailure', 'metastaticcancer', 'leukemia',\n",
       "       'immunosuppression', 'diabetes', 'mean_BUN', 'mean_Hgb',\n",
       "       'mean_WBC x 1000', 'mean_chloride', 'mean_creatinine', 'mean_glucose',\n",
       "       'mean_lactate', 'mean_pH', 'mean_paCO2', 'mean_paO2',\n",
       "       'mean_platelets x 1000', 'mean_potassium', 'mean_sodium',\n",
       "       'mean_total bilirubin', 'min_BUN', 'min_Hgb', 'min_WBC x 1000',\n",
       "       'min_chloride', 'min_creatinine', 'min_glucose', 'min_lactate',\n",
       "       'min_pH', 'min_paCO2', 'min_paO2', 'min_platelets x 1000',\n",
       "       'min_potassium', 'min_sodium', 'min_total bilirubin', 'max_BUN',\n",
       "       'max_Hgb', 'max_WBC x 1000', 'max_chloride', 'max_creatinine',\n",
       "       'max_glucose', 'max_lactate', 'max_pH', 'max_paCO2', 'max_paO2',\n",
       "       'max_platelets x 1000', 'max_potassium', 'max_sodium',\n",
       "       'max_total bilirubin', 'heartrate', 'respiration', 'temperature',\n",
       "       'sao2', 'systemicdiastolic', 'systemicmean', 'systemicsystolic',\n",
       "       'intaketotal_mean', 'intaketotal_max', 'intaketotal_min',\n",
       "       'intaketotal_last', 'outputtotal_mean', 'outputtotal_max',\n",
       "       'outputtotal_min', 'outputtotal_last', 'nettotal_mean', 'nettotal_max',\n",
       "       'nettotal_min', 'nettotal_last', 'ventstartoffset', 'ventendoffset'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0940974e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Remaining missing values:\n",
      "14398145\n"
     ]
    }
   ],
   "source": [
    "print(\" Remaining missing values:\")\n",
    "print(merged_df.isnull().sum().sum())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71d98f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Columns still with missing values:\n",
      "gender                        157\n",
      "age                           120\n",
      "admissionheight             14588\n",
      "hospitaldischargestatus     10954\n",
      "admissionweight             27683\n",
      "                            ...  \n",
      "nettotal_max                49993\n",
      "nettotal_min                49993\n",
      "nettotal_last               49993\n",
      "ventstartoffset            266081\n",
      "ventendoffset              266081\n",
      "Length: 97, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = merged_df.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "print(\" Columns still with missing values:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09099ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qb/06xhfcmx5yzc7t8swxtczfpw0000gn/T/ipykernel_37030/395119156.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"admissionweight\"].fillna(merged_df[\"admissionweight\"].median(), inplace=True)\n",
      "/var/folders/qb/06xhfcmx5yzc7t8swxtczfpw0000gn/T/ipykernel_37030/395119156.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"admitsource\"].fillna(\"Unknown\", inplace=True)\n",
      "/var/folders/qb/06xhfcmx5yzc7t8swxtczfpw0000gn/T/ipykernel_37030/395119156.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Unknown' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  merged_df[\"admitsource\"].fillna(\"Unknown\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "merged_df[\"admissionweight\"].fillna(merged_df[\"admissionweight\"].median(), inplace=True)\n",
    "merged_df[\"admitsource\"].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "lab_cols = [\"wbc\", \"hematocrit\", \"creatinine\", \"albumin\", \"pao2\", \"pco2\", \"bun\", \"glucose\", \"bilirubin\"]\n",
    "merged_df[lab_cols] = merged_df[lab_cols].apply(lambda x: x.fillna(x.median()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4ef3410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning ICU mortality columns...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qb/06xhfcmx5yzc7t8swxtczfpw0000gn/T/ipykernel_37030/3772035934.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df[col] = merged_df[col].replace({\"EXPIRED\": 1, \"ALIVE\": 0})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICU mortality columns cleaned and converted to numeric!\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning ICU mortality columns...\")\n",
    "\n",
    "# Define the ICU mortality columns\n",
    "icu_cols = [\"predictedicumortality\", \"actualicumortality\", \"predictedhospitalmortality\", \"actualhospitalmortality\"]\n",
    "\n",
    "for col in icu_cols:\n",
    "    merged_df[col] = merged_df[col].replace({\"EXPIRED\": 1, \"ALIVE\": 0})\n",
    "    merged_df[col] = pd.to_numeric(merged_df[col], errors=\"coerce\")  # Convert to numeric\n",
    "\n",
    "# Fill remaining NaN values with the median (should be 0 or 1)\n",
    "merged_df[icu_cols] = merged_df[icu_cols].apply(lambda x: x.fillna(x.median()), axis=0)\n",
    "\n",
    "print(\"ICU mortality columns cleaned and converted to numeric!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85fdf621",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_cols = [\"hepaticfailure\", \"metastaticcancer\", \"leukemia\", \"immunosuppression\", \"diabetes\"]\n",
    "merged_df[clinical_cols] = merged_df[clinical_cols].apply(lambda x: x.fillna(x.mode()[0]), axis=0)\n",
    "\n",
    "fluid_cols = [\"intaketotal_max\", \"intaketotal_min\", \"intaketotal_last\",\n",
    "              \"outputtotal_max\", \"outputtotal_min\", \"outputtotal_last\",\n",
    "              \"nettotal_max\", \"nettotal_min\", \"nettotal_last\"]\n",
    "merged_df[fluid_cols] = merged_df[fluid_cols].apply(lambda x: x.fillna(x.median()), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4949d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns still with missing values:\n",
      "gender                        157\n",
      "age                           120\n",
      "admissionheight             14588\n",
      "hospitaldischargestatus     10954\n",
      "urine                       64676\n",
      "                            ...  \n",
      "intaketotal_mean            49993\n",
      "outputtotal_mean            49993\n",
      "nettotal_mean               49993\n",
      "ventstartoffset            266081\n",
      "ventendoffset              266081\n",
      "Length: 68, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = merged_df.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "print(\"Columns still with missing values:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fc5734c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling missing values...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qb/06xhfcmx5yzc7t8swxtczfpw0000gn/T/ipykernel_37030/787757728.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"temperature\"].fillna(merged_df[\"temperature\"].median(), inplace=True)\n",
      "/var/folders/qb/06xhfcmx5yzc7t8swxtczfpw0000gn/T/ipykernel_37030/787757728.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"admissionheight\"].fillna(merged_df[\"admissionheight\"].median(), inplace=True)\n",
      "/var/folders/qb/06xhfcmx5yzc7t8swxtczfpw0000gn/T/ipykernel_37030/787757728.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"hospitaldischargestatus\"].fillna(merged_df[\"hospitaldischargestatus\"].mode()[0], inplace=True)\n",
      "/var/folders/qb/06xhfcmx5yzc7t8swxtczfpw0000gn/T/ipykernel_37030/787757728.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"gender\"].fillna(merged_df[\"gender\"].mode()[0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values handled successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qb/06xhfcmx5yzc7t8swxtczfpw0000gn/T/ipykernel_37030/787757728.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"age\"].fillna(merged_df[\"age\"].median(), inplace=True)\n",
      "/var/folders/qb/06xhfcmx5yzc7t8swxtczfpw0000gn/T/ipykernel_37030/787757728.py:36: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"admitdiagnosis\"].fillna(\"Unknown\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Handling missing values...\")\n",
    "\n",
    "# Fill missing temperature with median\n",
    "merged_df[\"temperature\"].fillna(merged_df[\"temperature\"].median(), inplace=True)\n",
    "\n",
    "# Fill missing blood pressure with mean per patient\n",
    "bp_cols = [ \"systemicdiastolic\", \"systemicsystolic\", \"systemicmean\"]\n",
    "merged_df[bp_cols] = merged_df[bp_cols].apply(lambda x: x.fillna(x.mean()), axis=0)\n",
    "\n",
    "# Fill missing intake/output values with median\n",
    "fluid_cols = [\"intaketotal_mean\", \"outputtotal_mean\", \"nettotal_mean\"]\n",
    "merged_df[fluid_cols] = merged_df[fluid_cols].apply(lambda x: x.fillna(x.median()), axis=0)\n",
    "\n",
    "# Fill missing lab results with median per test\n",
    "lab_cols = [col for col in merged_df.columns if \"mean_\" in col or \"min_\" in col or \"max_\" in col]\n",
    "merged_df[lab_cols] = merged_df[lab_cols].apply(lambda x: x.fillna(x.median()), axis=0)\n",
    "\n",
    "# Fill missing demographic data\n",
    "merged_df[\"admissionheight\"].fillna(merged_df[\"admissionheight\"].median(), inplace=True)\n",
    "merged_df[\"hospitaldischargestatus\"].fillna(merged_df[\"hospitaldischargestatus\"].mode()[0], inplace=True)\n",
    "merged_df[\"gender\"].fillna(merged_df[\"gender\"].mode()[0], inplace=True)\n",
    "\n",
    "# Convert age column to numeric, replacing '> 89' with 89\n",
    "merged_df[\"age\"] = merged_df[\"age\"].replace(\"> 89\", \"89\")  # Convert '> 89' to '89'\n",
    "merged_df[\"age\"] = pd.to_numeric(merged_df[\"age\"], errors=\"coerce\")  # Convert column to float\n",
    "\n",
    "# Fill missing values with median age\n",
    "merged_df[\"age\"] = pd.to_numeric(merged_df[\"age\"], errors=\"coerce\")\n",
    "merged_df[\"age\"].fillna(merged_df[\"age\"].median(), inplace=True)\n",
    "\n",
    "# Fill missing ICU scores with median\n",
    "score_cols = [\"apachescore\", \"acutephysiologyscore\"]\n",
    "merged_df[score_cols] = merged_df[score_cols].apply(lambda x: x.fillna(x.median()), axis=0)\n",
    "\n",
    "# Fill missing diagnosis with \"Unknown\"\n",
    "merged_df[\"admitdiagnosis\"].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "print(\"Missing values handled successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0c1285d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Handling final missing values...\n",
      " Final missing values handled successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\" Handling final missing values...\")\n",
    "\n",
    "# Fill missing vital signs with median per patient\n",
    "vital_cols = [\"urine\", \"respiratoryrate\", \"sodium\", \"meanbp\", \"ph\", \"heartrate\", \"respiration\", \"sao2\"]\n",
    "merged_df[vital_cols] = merged_df[vital_cols].apply(lambda x: x.fillna(x.median()), axis=0)\n",
    "\n",
    "# Fill missing Glasgow Coma Scale (GCS) values with median\n",
    "gcs_cols = [\"verbal\", \"motor\"]\n",
    "merged_df[gcs_cols] = merged_df[gcs_cols].apply(lambda x: x.fillna(x.median()), axis=0)\n",
    "\n",
    "print(\" Final missing values handled successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff297cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Converting categorical columns to string for Parquet compatibility...\n",
      " Categorical columns converted to string successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\" Converting categorical columns to string for Parquet compatibility...\")\n",
    "\n",
    "categorical_cols = [\"admitsource\", \"admitdiagnosis\"]\n",
    "\n",
    "merged_df[categorical_cols] = merged_df[categorical_cols].astype(str)\n",
    "\n",
    "print(\" Categorical columns converted to string successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e084ee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop(columns=[\"actualicumortality\",\"patientunitstayid\",\n",
    "                                    \"predictedicumortality\", \"predictedhospitalmortality\"\n",
    "                                   ], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75ed15fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Final dataset shape after correlation-based feature selection: (1908519, 83)\n",
      " Features retained: ['gender', 'age', 'admissionheight', 'hospitaladmitoffset', 'hospitaldischargeoffset', 'admissionweight', 'urine', 'wbc', 'respiratoryrate', 'sodium', 'meanbp', 'ph', 'hematocrit', 'creatinine', 'albumin', 'pao2', 'pco2', 'bun', 'glucose', 'bilirubin', 'acutephysiologyscore', 'apachescore', 'actualhospitalmortality', 'admitsource', 'verbal', 'motor', 'admitdiagnosis', 'hepaticfailure', 'metastaticcancer', 'leukemia', 'immunosuppression', 'diabetes', 'mean_BUN', 'mean_Hgb', 'mean_WBC x 1000', 'mean_chloride', 'mean_creatinine', 'mean_glucose', 'mean_lactate', 'mean_pH', 'mean_paCO2', 'mean_paO2', 'mean_platelets x 1000', 'mean_potassium', 'mean_sodium', 'mean_total bilirubin', 'min_BUN', 'min_WBC x 1000', 'min_chloride', 'min_creatinine', 'min_glucose', 'min_lactate', 'min_pH', 'min_paCO2', 'min_paO2', 'min_platelets x 1000', 'min_potassium', 'min_sodium', 'min_total bilirubin', 'max_BUN', 'max_Hgb', 'max_WBC x 1000', 'max_chloride', 'max_glucose', 'max_lactate', 'max_paCO2', 'max_paO2', 'max_platelets x 1000', 'max_potassium', 'max_sodium', 'heartrate', 'respiration', 'temperature', 'sao2', 'systemicdiastolic', 'systemicmean', 'systemicsystolic', 'intaketotal_mean', 'intaketotal_min', 'outputtotal_mean', 'outputtotal_min', 'ventstartoffset', 'ventendoffset']\n"
     ]
    }
   ],
   "source": [
    "features_to_remove_corr = [\n",
    "    \"max_creatinine\", \"intaketotal_max\", \"min_Hgb\", \"nettotal_mean\", \"nettotal_last\",\n",
    "     \"hospitaldischargestatus\", \"outputtotal_last\", \"intaketotal_last\",\n",
    "    \"max_pH\", \"nettotal_max\", \"max_total bilirubin\", \"nettotal_min\",\n",
    "     \"outputtotal_max\"\n",
    "]\n",
    "\n",
    "\n",
    "merged_df = merged_df.drop(columns=features_to_remove_corr, errors=\"ignore\")\n",
    "\n",
    "print(f\" Final dataset shape after correlation-based feature selection: {merged_df.shape}\")\n",
    "print(f\" Features retained: {list(merged_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71da831c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Removed redundant min/max lab test features.\n",
      " Updated dataset shape: (1908519, 57)\n",
      " Remaining columns: ['gender', 'age', 'admissionheight', 'hospitaladmitoffset', 'hospitaldischargeoffset', 'admissionweight', 'urine', 'wbc', 'respiratoryrate', 'sodium', 'meanbp', 'ph', 'hematocrit', 'creatinine', 'albumin', 'pao2', 'pco2', 'bun', 'glucose', 'bilirubin', 'acutephysiologyscore', 'apachescore', 'actualhospitalmortality', 'admitsource', 'verbal', 'motor', 'admitdiagnosis', 'hepaticfailure', 'metastaticcancer', 'leukemia', 'immunosuppression', 'diabetes', 'mean_BUN', 'mean_Hgb', 'mean_WBC x 1000', 'mean_chloride', 'mean_creatinine', 'mean_glucose', 'mean_lactate', 'mean_pH', 'mean_paCO2', 'mean_paO2', 'mean_platelets x 1000', 'mean_potassium', 'mean_sodium', 'mean_total bilirubin', 'heartrate', 'respiration', 'temperature', 'sao2', 'systemicdiastolic', 'systemicmean', 'systemicsystolic', 'intaketotal_mean', 'outputtotal_mean', 'ventstartoffset', 'ventendoffset']\n"
     ]
    }
   ],
   "source": [
    "features_to_remove = [\n",
    "    \"min_BUN\", \"max_BUN\", \"min_WBC x 1000\", \"max_WBC x 1000\",\n",
    "    \"min_creatinine\", \"max_creatinine\", \"min_glucose\", \"max_glucose\",\n",
    "    \"min_pH\", \"max_pH\", \"min_paO2\", \"max_paO2\", \"min_paCO2\", \"max_paCO2\",\n",
    "    \"min_platelets x 1000\", \"max_platelets x 1000\", \"min_potassium\", \"max_potassium\",\n",
    "    \"min_sodium\", \"max_sodium\", \"min_total bilirubin\", \"max_total bilirubin\", \"min_chloride\", \n",
    "    \"max_chloride\", \"min_lactate\", \"max_lactate\", \"max_Hgb\",\n",
    "    \"intaketotal_min\", \"outputtotal_min\"\n",
    "]\n",
    "\n",
    "\n",
    "merged_df = merged_df.drop(columns=features_to_remove, errors=\"ignore\")\n",
    "\n",
    "print(\" Removed redundant min/max lab test features.\")\n",
    "print(f\" Updated dataset shape: {merged_df.shape}\")\n",
    "print(f\" Remaining columns: {list(merged_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f6eb4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"LOS_days\"] = (merged_df[\"hospitaldischargeoffset\"] - merged_df[\"hospitaladmitoffset\"]) / (60 * 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3749ba3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'age', 'admissionheight', 'hospitaladmitoffset',\n",
       "       'hospitaldischargeoffset', 'admissionweight', 'urine', 'wbc',\n",
       "       'respiratoryrate', 'sodium', 'meanbp', 'ph', 'hematocrit', 'creatinine',\n",
       "       'albumin', 'pao2', 'pco2', 'bun', 'glucose', 'bilirubin',\n",
       "       'acutephysiologyscore', 'apachescore', 'actualhospitalmortality',\n",
       "       'admitsource', 'verbal', 'motor', 'admitdiagnosis', 'hepaticfailure',\n",
       "       'metastaticcancer', 'leukemia', 'immunosuppression', 'diabetes',\n",
       "       'mean_BUN', 'mean_Hgb', 'mean_WBC x 1000', 'mean_chloride',\n",
       "       'mean_creatinine', 'mean_glucose', 'mean_lactate', 'mean_pH',\n",
       "       'mean_paCO2', 'mean_paO2', 'mean_platelets x 1000', 'mean_potassium',\n",
       "       'mean_sodium', 'mean_total bilirubin', 'heartrate', 'respiration',\n",
       "       'temperature', 'sao2', 'systemicdiastolic', 'systemicmean',\n",
       "       'systemicsystolic', 'intaketotal_mean', 'outputtotal_mean',\n",
       "       'ventstartoffset', 'ventendoffset', 'LOS_days'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af0a0ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Estimated size of merged_df: 1.12 GB\n"
     ]
    }
   ],
   "source": [
    "merged_df_size = merged_df.memory_usage(deep=True).sum() / (1024 ** 3)\n",
    "print(f\" Estimated size of merged_df: {merged_df_size:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ff0bef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Estimated size of merged_df: 1.12 GB\n",
      " Merged dataset saved as Parquet: merged_eicu_data.parquet\n"
     ]
    }
   ],
   "source": [
    "merged_df_size = merged_df.memory_usage(deep=True).sum() / (1024 ** 3)\n",
    "print(f\" Estimated size of merged_df: {merged_df_size:.2f} GB\")\n",
    "\n",
    "output_path = \"merged_eicu_data.parquet\"\n",
    "\n",
    "merged_df.to_parquet(output_path, index=False)\n",
    "print(f\" Merged dataset saved as Parquet: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bfcdd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
