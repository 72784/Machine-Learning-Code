{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ca5078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e77a8d93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aff8731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading merged dataset from Parquet...\n",
      " Loaded dataset with 116,426 rows and 42 columns.\n"
     ]
    }
   ],
   "source": [
    "print(\" Loading merged dataset from Parquet...\")\n",
    "mimic_df = pd.read_parquet(\"merged_mimic_data.parquet\")\n",
    "print(f\" Loaded dataset with {mimic_df.shape[0]:,} rows and {mimic_df.shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2cf5d35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "selected_features = ['age', 'admissionweight', 'respiratoryrate', 'ph', 'bun',\n",
    "       'glucose', 'motor',\n",
    "       'mean_BUN', 'mean_Hgb', 'mean_WBC x 1000', 'mean_chloride',\n",
    "       'mean_creatinine', 'mean_glucose', 'mean_lactate', 'mean_pH',\n",
    "       'mean_paCO2', 'mean_paO2', 'mean_platelets x 1000', 'mean_potassium',\n",
    "       'mean_sodium', 'mean_total bilirubin', 'heartrate', 'respiration',\n",
    "        'sao2', 'systemicdiastolic', 'systemicmean',\n",
    "       'systemicsystolic', 'outputtotal_mean']\n",
    "\n",
    "X = mimic_df[selected_features]\n",
    "y = mimic_df[\"actualhospitalmortality\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e638fd87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f87932d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model_pretty(name, y_test, y_pred, y_prob, y, n_classes, results):\n",
    "    if n_classes == 2:\n",
    "        if y_prob.ndim == 2 and y_prob.shape[1] == 2:\n",
    "            roc_auc = roc_auc_score(y_test, y_prob[:, 1])\n",
    "        else:\n",
    "            roc_auc = roc_auc_score(y_test, y_prob.flatten())\n",
    "    else:\n",
    "        roc_auc = roc_auc_score(\n",
    "            label_binarize(y_test, classes=np.unique(y)),\n",
    "            y_prob,\n",
    "            average='macro',\n",
    "            multi_class='ovo'\n",
    "        )\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='macro')\n",
    "    rec = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Evaluation of {name} on Test Set:\")\n",
    "    print(f\"  Accuracy : {acc:.4f}\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall   : {rec:.4f}\")\n",
    "    print(f\"  AUC-ROC  : {roc_auc:.4f}\\n\")\n",
    "    print(\"Detailed Report:\\n\")\n",
    "    print(classification_report(y_test, y_pred, digits=2))\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"ROC-AUC\": roc_auc\n",
    "    })\n",
    "\n",
    "\n",
    "results = []\n",
    "n_classes = len(np.unique(y_train))\n",
    "y = np.concatenate([y_train, y_test])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9882a016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Evaluation of Logistic Regression  on Test Set:\n",
      "  Accuracy : 0.9268\n",
      "  Precision: 0.7692\n",
      "  Recall   : 0.6822\n",
      "  AUC-ROC  : 0.8552\n",
      "\n",
      "Detailed Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96     21346\n",
      "           1       0.59      0.39      0.47      1940\n",
      "\n",
      "    accuracy                           0.93     23286\n",
      "   macro avg       0.77      0.68      0.72     23286\n",
      "weighted avg       0.92      0.93      0.92     23286\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "logr_model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(max_iter=2000))\n",
    "])\n",
    "logr_model.fit(X_train, y_train)\n",
    "\n",
    "y_prob_logr = logr_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_pred_logr = (y_prob_logr > 0.3).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "evaluate_model_pretty(\"Logistic Regression \", y_test, y_pred_logr, y_prob_logr, y, n_classes, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8fa9e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Evaluation of Gaussian Naive Bayes on Test Set:\n",
      "  Accuracy : 0.8408\n",
      "  Precision: 0.6169\n",
      "  Recall   : 0.7163\n",
      "  AUC-ROC  : 0.8021\n",
      "\n",
      "Detailed Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91     21346\n",
      "           1       0.28      0.57      0.37      1940\n",
      "\n",
      "    accuracy                           0.84     23286\n",
      "   macro avg       0.62      0.72      0.64     23286\n",
      "weighted avg       0.90      0.84      0.86     23286\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "nb_model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "nb_model.fit(X_train, y_train)\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "y_prob_nb = nb_model.predict_proba(X_test)\n",
    "\n",
    "y_prob_nb = nb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_pred_nb = (y_prob_nb > 0.3).astype(int)\n",
    "\n",
    "evaluate_model_pretty(\"Gaussian Naive Bayes\", y_test, y_pred_nb, y_prob_nb, y, n_classes, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16bbacbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Evaluation of K-Nearest Neighbors  on Test Set:\n",
      "  Accuracy : 0.9066\n",
      "  Precision: 0.6993\n",
      "  Recall   : 0.7183\n",
      "  AUC-ROC  : 0.8463\n",
      "\n",
      "Detailed Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     21346\n",
      "           1       0.45      0.49      0.47      1940\n",
      "\n",
      "    accuracy                           0.91     23286\n",
      "   macro avg       0.70      0.72      0.71     23286\n",
      "weighted avg       0.91      0.91      0.91     23286\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "knn_model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "y_prob_knn = knn_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_pred_knn = (y_prob_knn > 0.3).astype(int)\n",
    "\n",
    "evaluate_model_pretty(\"K-Nearest Neighbors \", y_test, y_pred_knn, y_prob_knn, y, n_classes, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "107c7989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parthshiroya/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/parthshiroya/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/parthshiroya/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/parthshiroya/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/parthshiroya/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Evaluation of LinearSVC + Calibration on Test Set:\n",
      "  Accuracy : 0.9280\n",
      "  Precision: 0.7839\n",
      "  Recall   : 0.6596\n",
      "  AUC-ROC  : 0.8544\n",
      "\n",
      "Detailed Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96     21346\n",
      "           1       0.63      0.34      0.44      1940\n",
      "\n",
      "    accuracy                           0.93     23286\n",
      "   macro avg       0.78      0.66      0.70     23286\n",
      "weighted avg       0.92      0.93      0.92     23286\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parthshiroya/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "svc_model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', CalibratedClassifierCV(LinearSVC(max_iter=1000), cv=3))\n",
    "])\n",
    "svc_model.fit(X_train, y_train)\n",
    "y_pred_svc = svc_model.predict(X_test)\n",
    "y_prob_svc = svc_model.predict_proba(X_test)\n",
    "\n",
    "y_prob_svc = y_prob_svc[:, 1]\n",
    "y_pred_svc = (y_prob_svc > 0.3).astype(int)\n",
    "\n",
    "evaluate_model_pretty(\"LinearSVC + Calibration\", y_test, y_pred_svc, y_prob_svc, y, n_classes, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fefec73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Random Forest with Class Balancing...\n",
      "\n",
      "================================================================================\n",
      "Evaluation of Random Forest (Balanced) on Test Set:\n",
      "  Accuracy : 0.9354\n",
      "  Precision: 0.8214\n",
      "  Recall   : 0.6920\n",
      "  AUC-ROC  : 0.9045\n",
      "\n",
      "Detailed Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97     21346\n",
      "           1       0.70      0.40      0.51      1940\n",
      "\n",
      "    accuracy                           0.94     23286\n",
      "   macro avg       0.82      0.69      0.74     23286\n",
      "weighted avg       0.93      0.94      0.93     23286\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\" Training Random Forest with Class Balancing...\")\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100, max_depth=10, \n",
    "    random_state=42, n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_prob_rf = rf_model.predict_proba(X_test)  \n",
    "\n",
    "y_prob_rf = y_prob_rf[:, 1]\n",
    "\n",
    "threshold = 0.3\n",
    "y_pred_rf = (y_prob_rf > threshold).astype(int)\n",
    "\n",
    "evaluate_model_pretty(\"Random Forest (Balanced)\", y_test, y_pred_rf, y_prob_rf, y, n_classes, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b4ea245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Evaluation of XGBoost (Default Params) on Test Set:\n",
      "  Accuracy : 0.9301\n",
      "  Precision: 0.7718\n",
      "  Recall   : 0.7641\n",
      "  AUC-ROC  : 0.9414\n",
      "\n",
      "Detailed Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96     21346\n",
      "           1       0.58      0.56      0.57      1940\n",
      "\n",
      "    accuracy                           0.93     23286\n",
      "   macro avg       0.77      0.76      0.77     23286\n",
      "weighted avg       0.93      0.93      0.93     23286\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, classification_report\n",
    "\n",
    "# Train a simple XGBoost model (default settings)\n",
    "xgb_model_simple = xgb.XGBClassifier(random_state=42)\n",
    "xgb_model_simple.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions\n",
    "y_pred_xgb_simple = xgb_model_simple.predict(X_test)\n",
    "y_prob_xgb_simple = xgb_model_simple.predict_proba(X_test)[:, 1]  # Positive class probability\n",
    "\n",
    "y_pred_xgb_simple = (y_prob_xgb_simple > 0.3).astype(int)\n",
    "\n",
    "# Use evaluate_model_pretty for consistent evaluation\n",
    "evaluate_model_pretty(\"XGBoost (Default Params)\", y_test, y_pred_xgb_simple, y_prob_xgb_simple, y, n_classes, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ad059e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training XGBoost with Best Hyperparameters...\n",
      "\n",
      "================================================================================\n",
      "Evaluation of XGBoost (0.3 threshold) on Test Set:\n",
      "  Accuracy : 0.9316\n",
      "  Precision: 0.7768\n",
      "  Recall   : 0.7710\n",
      "  AUC-ROC  : 0.9474\n",
      "\n",
      "Detailed Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96     21346\n",
      "           1       0.59      0.58      0.58      1940\n",
      "\n",
      "    accuracy                           0.93     23286\n",
      "   macro avg       0.78      0.77      0.77     23286\n",
      "weighted avg       0.93      0.93      0.93     23286\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "print(\" Training XGBoost with Best Hyperparameters...\")\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=1,\n",
    "    min_child_weight=1,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "y_prob_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "threshold = 0.3\n",
    "y_pred_xgb = (y_prob_xgb > threshold).astype(int)\n",
    "\n",
    "evaluate_model_pretty(\"XGBoost (0.3 threshold)\", y_test, y_pred_xgb, y_prob_xgb, y, n_classes, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91e08da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Neural Network with Class Weighting...\n",
      "Epoch 1/10 - Loss: 0.7433\n",
      "Epoch 2/10 - Loss: 0.9097\n",
      "Epoch 3/10 - Loss: 0.7943\n",
      "Epoch 4/10 - Loss: 0.9005\n",
      "Epoch 5/10 - Loss: 0.8806\n",
      "Epoch 6/10 - Loss: 0.8571\n",
      "Epoch 7/10 - Loss: 0.7585\n",
      "Epoch 8/10 - Loss: 0.7295\n",
      "Epoch 9/10 - Loss: 0.7547\n",
      "Epoch 10/10 - Loss: 0.7388\n",
      "Training Completed!\n",
      "\n",
      "================================================================================\n",
      "Evaluation of Neural Network (PyTorch) on Test Set:\n",
      "  Accuracy : 0.6649\n",
      "  Precision: 0.5914\n",
      "  Recall   : 0.7891\n",
      "  AUC-ROC  : 0.9007\n",
      "\n",
      "Detailed Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.64      0.78     21346\n",
      "           1       0.19      0.94      0.32      1940\n",
      "\n",
      "    accuracy                           0.66     23286\n",
      "   macro avg       0.59      0.79      0.55     23286\n",
      "weighted avg       0.92      0.66      0.74     23286\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)  # 2D\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "pos_weight_value = (len(y_train_tensor) - y_train_tensor.sum()) / y_train_tensor.sum()\n",
    "pos_weight = torch.tensor([pos_weight_value.item()])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=512, shuffle=True)\n",
    "\n",
    "\n",
    "class ICU_NN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ICU_NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return self.fc3(x)  \n",
    "\n",
    "\n",
    "model = ICU_NN(X_train.shape[1])\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "print(\" Training Neural Network with Class Weighting...\")\n",
    "for epoch in range(10):\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/10 - Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "print(\"Training Completed!\")\n",
    "with torch.no_grad():\n",
    "    logits = model(X_test_tensor)\n",
    "    probs = torch.sigmoid(logits) \n",
    "    y_pred = (probs > 0.3).float()\n",
    "\n",
    "    y_test_np = y_test_tensor.numpy().astype(int).flatten()\n",
    "    y_pred_np = y_pred.numpy().astype(int).flatten()\n",
    "    y_prob_np = probs.numpy()  \n",
    "\n",
    "    evaluate_model_pretty(\"Neural Network (PyTorch)\", y_test_np, y_pred_np, y_prob_np, y, n_classes, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66cd80d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of Combined Ensemble Model on Test Set:\n",
      "Accuracy: 0.8110\n",
      "Precision: 0.2891\n",
      "Recall: 0.8696\n",
      "AUC-ROC: 0.9251\n",
      "\n",
      "Detailed Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.81      0.89     21346\n",
      "           1       0.29      0.87      0.43      1940\n",
      "\n",
      "    accuracy                           0.81     23286\n",
      "   macro avg       0.64      0.84      0.66     23286\n",
      "weighted avg       0.93      0.81      0.85     23286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_prob = y_prob_np.flatten()\n",
    "\n",
    "ensemble_prob = (nn_prob + y_prob_xgb) / 2.0\n",
    "\n",
    "ensemble_pred = (ensemble_prob > 0.3).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_test, ensemble_pred)\n",
    "precision = precision_score(y_test, ensemble_pred)\n",
    "recall = recall_score(y_test, ensemble_pred)\n",
    "roc_auc = roc_auc_score(y_test, ensemble_prob)\n",
    "\n",
    "print(\"Evaluation of Combined Ensemble Model on Test Set:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
    "print(\"\\nDetailed Report:\\n\")\n",
    "print(classification_report(y_test, ensemble_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "910de1d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Model  Accuracy  Precision    Recall   ROC-AUC\n",
      "0      Logistic Regression   0.926780   0.769212  0.682173  0.855219\n",
      "1      Gaussian Naive Bayes  0.840806   0.616904  0.716350  0.802104\n",
      "2      K-Nearest Neighbors   0.906596   0.699315  0.718260  0.846326\n",
      "3   LinearSVC + Calibration  0.927982   0.783908  0.659632  0.854437\n",
      "4  Random Forest (Balanced)  0.935412   0.821419  0.692036  0.904537\n",
      "5  XGBoost (Default Params)  0.930087   0.771775  0.764110  0.941392\n",
      "6   XGBoost (0.3 threshold)  0.931633   0.776765  0.771045  0.947391\n",
      "7  Neural Network (PyTorch)  0.664949   0.591416  0.789132  0.900748\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8475f53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model saved successfully!\n",
      " Logistic Regression model saved successfully!\n",
      "Gaussian Naive Bayes model saved successfully!\n",
      " K-Nearest Neighbors model saved successfully!\n",
      "LinearSVC + Calibration model saved successfully!\n",
      " XGBoost model saved as 'xgb_simple_model.pkl'\n",
      " XGBoost model saved successfully!\n",
      " Neural Network model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(rf_model, \"random_forest_mimic.pkl\")\n",
    "print(\"Random Forest model saved successfully!\")\n",
    "\n",
    "joblib.dump(logr_model, \"logistic_regression_mimic.pkl\")\n",
    "print(\" Logistic Regression model saved successfully!\")\n",
    "\n",
    "joblib.dump(nb_model, \"naive_bayes_mimic.pkl\")\n",
    "print(\"Gaussian Naive Bayes model saved successfully!\")\n",
    "\n",
    "joblib.dump(knn_model, \"knn_mimic.pkl\")\n",
    "print(\" K-Nearest Neighbors model saved successfully!\")\n",
    "\n",
    "joblib.dump(svc_model, \"linear_svc_calibrated_mimic.pkl\")\n",
    "print(\"LinearSVC + Calibration model saved successfully!\")\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(xgb_model_simple, \"xgb_simple_model.pkl\")\n",
    "print(\" XGBoost model saved as 'xgb_simple_model.pkl'\")\n",
    "\n",
    "joblib.dump(xgb_model, \"xgb_mimic.pkl\")\n",
    "print(\" XGBoost model saved successfully!\")\n",
    "\n",
    "torch.save(model.state_dict(), \"mimic_mortality.pth\")\n",
    "print(\" Neural Network model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16496e3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'admissionweight', 'respiratoryrate', 'ph', 'bun', 'glucose',\n",
       "       'motor', 'mean_BUN', 'mean_Hgb', 'mean_WBC x 1000', 'mean_chloride',\n",
       "       'mean_creatinine', 'mean_glucose', 'mean_lactate', 'mean_pH',\n",
       "       'mean_paCO2', 'mean_paO2', 'mean_platelets x 1000', 'mean_potassium',\n",
       "       'mean_sodium', 'mean_total bilirubin', 'heartrate', 'respiration',\n",
       "       'sao2', 'systemicdiastolic', 'systemicmean', 'systemicsystolic',\n",
       "       'outputtotal_mean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "489dcae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1089c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
